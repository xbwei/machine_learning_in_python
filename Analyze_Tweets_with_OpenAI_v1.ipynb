{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc3883c",
   "metadata": {},
   "source": [
    "# Analyze Twitter Data with OpenAI V1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e679fb6",
   "metadata": {},
   "source": [
    "This notebook assumes that your Tweets are collected with Twitter API V1, or the Tweets are orgianzied as:\n",
    "```\n",
    "{\n",
    "id:123,\n",
    "text:'abc',\n",
    "...\n",
    "}\n",
    "\n",
    "```\n",
    "If you Tweets are collected with Twitter API V2 or organized in a different foramt, please use the code at [V1](V1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcc5219",
   "metadata": {},
   "source": [
    "## Install Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e9eb5",
   "metadata": {},
   "source": [
    "We need the [pymongo](https://pypi.org/project/pymongo/) to manage the MongoDB database, and [openai](https://github.com/openai/openai-python) to call the OpenAI APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e207189b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Obtaining dependency information for pymongo from https://files.pythonhosted.org/packages/5e/97/6fc527b749f4af354042c43b7032d0734923be2dad6c8ffdd28b469b8e93/pymongo-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pymongo-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Obtaining dependency information for dnspython<3.0.0,>=1.16.0 from https://files.pythonhosted.org/packages/f6/b4/0a9bee52c50f226a3cbfb54263d02bb421c7f2adc136520729c2c689c1e5/dnspython-2.4.2-py3-none-any.whl.metadata\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading pymongo-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.4.2 pymongo-4.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0779bc84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/dd/82/b92f73453ea318c0d46f31aeb56e9d94a42606c010fb72a513f4a3cd4bac/openai-1.1.2-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (3.7.1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/82/61/a5fca4a1e88e40969bbd0cf0d981f3aa76d5057db160b94f49603fc18740/httpx-0.25.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.25.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Obtaining dependency information for pydantic<3,>=1.9.0 from https://files.pythonhosted.org/packages/73/66/0a72c9fcde42e5650c8d8d5c5c1873b9a3893018020c77ca8eb62708b923/pydantic-2.4.2-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.6/158.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.1.2)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore from https://files.pythonhosted.org/packages/7c/bd/8f4e676af570d8990e02e3f4cefba7c0c506f2b2ce63f086e0cb939b6e1e/httpcore-1.0.1-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for pydantic-core==2.10.1 from https://files.pythonhosted.org/packages/86/67/d36e2237d84ac96f400e29586da1e21eabf9aa227fc9c3e4410fbc6408de/pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.1.2-py3-none-any.whl (217 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.9/217.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pydantic-core, h11, distro, annotated-types, pydantic, httpcore, httpx, openai\n",
      "Successfully installed annotated-types-0.6.0 distro-1.8.0 h11-0.14.0 httpcore-1.0.1 httpx-0.25.1 openai-1.1.2 pydantic-2.4.2 pydantic-core-2.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12530bd4",
   "metadata": {},
   "source": [
    "## Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d944e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "from pprint import pprint\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17f430f",
   "metadata": {},
   "source": [
    "## Load the authorization info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52260a80",
   "metadata": {},
   "source": [
    "Save the database connection info and API key in a config.ini file and use the configparse to load the authorization info.\n",
    "\n",
    "The config.ini file should look like:\n",
    "``` \n",
    "[myopenai]\n",
    "openai_api = <your openai API>\n",
    "\n",
    "[mymongo]\n",
    "connection = <your monogdb connection>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d56a489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser(interpolation=None)\n",
    "config.read('config.ini')\n",
    "\n",
    "openai_api_key   = config['myopenai']['openai_api']\n",
    "\n",
    "mongod_connect = config['mymongo']['connection']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c50e000",
   "metadata": {},
   "source": [
    "## Connect to the MongoDB cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d694834",
   "metadata": {},
   "source": [
    "We will connect to the MongoDB database that contains the tweet data. You need to change the database name and collection name to match your settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9102f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(mongod_connect)\n",
    "db = client.tweet # use or create a database named tweet\n",
    "tweet_collection = db.gun_va #use or create a collection named gun_va\n",
    "# tweet_collection.create_index([(\"tweet.id\", pymongo.ASCENDING)],unique = True) # make sure the collected tweets are unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e6941d",
   "metadata": {},
   "source": [
    "## Extract Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0099a8b",
   "metadata": {},
   "source": [
    "Search the Tweets you are intrested.\n",
    "You can use [MongoDB Compass](https://www.mongodb.com/try/download/compass) to help you write the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8420470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following code is generated in MongoDB Compass to find the top 100 tweets \n",
    "with a key word of 'shooting', ordered by the favorite count\n",
    "'''\n",
    "filter={\n",
    "    '$text': {\n",
    "        '$search': 'shooting'\n",
    "    }\n",
    "}\n",
    "project={\n",
    "    'id': 1, \n",
    "    'text': 1\n",
    "}\n",
    "sort=list({\n",
    "    'favorite_count': -1\n",
    "}.items())\n",
    "limit=100\n",
    "result = client['tweet']['gun_va'].find(\n",
    "  filter=filter,\n",
    "  projection=project,\n",
    "  sort=sort,\n",
    "  limit=limit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76637a42",
   "metadata": {},
   "source": [
    "Save the extracted Tweets into the ```tweet_data``` list. Remove URLs and extract lines to save the tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f7dbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "for tweet in result:\n",
    "    text_without_urls = re.sub(url_pattern, '', tweet['text'])\n",
    "    tweet_data.append({'tweet_id':tweet['id'],'tweet_text':text_without_urls.replace('\\n','')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "26b9f24a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets:  73\n"
     ]
    }
   ],
   "source": [
    "print('Number of tweets: ',len(tweet_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0764c0",
   "metadata": {},
   "source": [
    "## Set up OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641989e5",
   "metadata": {},
   "source": [
    "Load the OpenAI API key and set the API parameters. \n",
    "- Model type: use ```gpt-3.5-turbo``` by default, and you can use the [avaiabel models](https://platform.openai.com/docs/models/continuous-model-upgrades).\n",
    "- Token estimate: 100 tokens ~= 75 words in English. You can get a more accurate estimate at [Tokenier](https://platform.openai.com/tokenizer).\n",
    "- Temperature: use default value 0. Lower temperature result in more consistent outputs, while higher values generate more diverse and creative results\n",
    "\n",
    "We also C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1235902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "model=\"gpt-3.5-turbo\"\n",
    "temperature=0\n",
    "\n",
    "\n",
    "\n",
    "def openai_help(prompt, model=model, temperature =temperature ):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1564c1",
   "metadata": {},
   "source": [
    "## Sentiment anlysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f10f947",
   "metadata": {},
   "source": [
    "Analyze the sentiment of each tweet and save the result to the MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "271cf78d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:32<00:00,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for tweet in tqdm(tweet_data):\n",
    "  \n",
    "    prompt = f\"\"\"\n",
    "    What is the sentiment of the following tweet, \n",
    "    tweet text: {tweet['tweet_text']}\n",
    "    return  the result with one word as positive, neutral,or negative\n",
    " \n",
    "    \"\"\"\n",
    "#     print(prompt)\n",
    "    try:\n",
    "        sentiment_result =openai_help(prompt)\n",
    "    #     print(sentiment_result)\n",
    "\n",
    "        tweet_collection.update_one(\n",
    "            {'id':tweet['tweet_id']},\n",
    "            {\"$set\":{'sentiment':sentiment_result}}\n",
    "        )\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f57010",
   "metadata": {},
   "source": [
    "## Translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae92b5",
   "metadata": {},
   "source": [
    "Translate each tweet into a different language, and save the result to the MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "55bfe879",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [01:33<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "for tweet in tqdm(tweet_data):\n",
    "  \n",
    "    prompt = f\"\"\"\n",
    "    Translate the follwoing tweet into Chinese\n",
    "    tweet text: {tweet['tweet_text']}\n",
    " \n",
    "    \"\"\"\n",
    "#     print(prompt)\n",
    "    try:\n",
    "        translate_result =openai_help(prompt)\n",
    "#         print(translate_result)\n",
    "\n",
    "        tweet_collection.update_one(\n",
    "            {'id':tweet['tweet_id']},\n",
    "            {\"$set\":{'translate':translate_result}}\n",
    "        )\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d4ae49",
   "metadata": {},
   "source": [
    "## Identify emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c81c2f",
   "metadata": {},
   "source": [
    "Identify whether a tweet expresses anger, and save the result to the MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ee5457f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:30<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "for tweet in tqdm(tweet_data):\n",
    "  \n",
    "    prompt = f\"\"\"\n",
    "    Does the following tweet express anger?\n",
    "    Provide the result as eitehr True or False.\n",
    "    tweet text: {tweet['tweet_text']}\n",
    " \n",
    "    \"\"\"\n",
    "#     print(prompt)\n",
    "    try:\n",
    "        emotion_result =openai_help(prompt)\n",
    "    #     print(emotion_result)\n",
    "\n",
    "        tweet_collection.update_one(\n",
    "                {'id':tweet['tweet_id']},\n",
    "                {\"$set\":{'anger':emotion_result}}\n",
    "            )\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e8ffd0",
   "metadata": {},
   "source": [
    "## Extract entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f3066f",
   "metadata": {},
   "source": [
    "Extract persons and organzations names from each tweet and save the result to the MongoDB database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c72c10d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:51<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "for tweet in tqdm(tweet_data):\n",
    "  \n",
    "    prompt = f\"\"\"\n",
    "    Identify the person name or organzation names from the following tweet,\n",
    "    tweet text: {tweet['tweet_text']}\n",
    "    format the response as a JSON document with person and organzation the keys.\n",
    "    If the information is not presented, use \"unknow\"\n",
    "    \"\"\"\n",
    "#     print(prompt)\n",
    "    try:\n",
    "        extract_result =openai_help(prompt)\n",
    "#         print(extract_result)\n",
    "\n",
    "        tweet_collection.update_one(\n",
    "                {'id':tweet['tweet_id']},\n",
    "                {\"$set\":{'extracted_item':json.loads(extract_result)}}\n",
    "                )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364887f5",
   "metadata": {},
   "source": [
    "## Smmuarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84fff0d",
   "metadata": {},
   "source": [
    "Summarize the tweet texts with a specific focus, and save the result to the MongoDB database.\n",
    "Due to the token limitation, each time we sumarize no more than 50 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7ab3b7dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tweets mention various aspects of the election, including gun control and mass shootings. Some tweets express frustration with the lack of action on gun control, while others argue that gun control is not the solution to preventing shootings. There is also mention of politicians being exposed by mass shooting survivors and criticism of the NRA.\n",
      "The tweets discuss various aspects of gun control in relation to mass shootings. Some argue for stricter gun control laws as a way to prevent shootings, while others believe mental health and other factors should be addressed. There is criticism of politicians offering thoughts and prayers instead of passing legislation. The tweets also mention the potential for gun control discussions to fade away until the next shooting occurs.\n"
     ]
    }
   ],
   "source": [
    "# Define the batch size\n",
    "batch_size = 50\n",
    "\n",
    "start_index = 0\n",
    "\n",
    "\n",
    "while start_index < len(tweet_data):\n",
    "    batch = tweet_data[start_index:start_index + batch_size]\n",
    "\n",
    "    tweet_id_list =[]\n",
    "    tweet_text_summary =''\n",
    "    \n",
    "    for tweet in batch:\n",
    "        tweet_id_list.append(tweet['tweet_id'])\n",
    "        tweet_text_summary = tweet_text_summary+'.'+tweet['tweet_text']\n",
    "        \n",
    "    prompt = f\"\"\"\n",
    "    Sumarize the following tweets in at most 50 words\n",
    "    and focusing on any spect that mentioned election\n",
    "    tweet text: {tweet_text_summary}\n",
    " \n",
    "    \"\"\"\n",
    "#     print(prompt)\n",
    "    try:\n",
    "        summary_result =openai_help(prompt)\n",
    "        \n",
    "        tweet_summary = db.tweet_summary #use or create a collection named gun_va\n",
    "        tweet_summary.insert_one({'id_list':tweet_id_list,\n",
    "                            'tweet_text_summary':summary_result})\n",
    "        print(summary_result)\n",
    "    except:\n",
    "        pass\n",
    "    start_index += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea5f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
